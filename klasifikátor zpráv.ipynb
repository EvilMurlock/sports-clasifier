{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9ce21229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "seed = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab1605",
   "metadata": {},
   "source": [
    "Loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b62196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: injuries.csv\n",
      "Loading: interview.csv\n",
      "Loading: prematch.csv\n",
      "Loading: reaction.csv\n",
      "Loading: report.csv\n",
      "Loading: transfers.csv\n",
      "['Injuries' 'Interview' 'Pre-Match' 'Reaction' 'Report' 'Transfers']\n",
      "Weights: [1.0, 1.0, 1.0, 0.1, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.107919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  1500.000000\n",
       "mean      2.800000\n",
       "std       1.107919\n",
       "min       0.000000\n",
       "25%       3.000000\n",
       "50%       3.000000\n",
       "75%       3.000000\n",
       "max       5.000000"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '.' # current file\n",
    "all_files = glob.glob(\"*.csv\") # gets csv files in current folder\n",
    "\n",
    "li = []\n",
    "for filename in all_files: # we load all csv files\n",
    "    print(\"Loading: \"+str(filename))\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "data = pd.concat(li, axis=0, ignore_index=True) # we combine all dataframes into a single dataframe.\n",
    "\n",
    "# we replace all empty fields with empty strings\n",
    "data.fillna('')\n",
    "data.perex = data.perex.fillna('')\n",
    "\n",
    "# we combine both text collumns into one and forget the originals\n",
    "data[\"text\"] = data[\"title\"] + \" \" + data[\"perex\"]\n",
    "data = data.drop('title', axis=1)\n",
    "data = data.drop('perex', axis=1)\n",
    "\n",
    "# we find all the classes\n",
    "classes_ = data['label'].unique()\n",
    "print(classes_)\n",
    "\n",
    "# we create a dictionary of classes and their indexes\n",
    "classes = {}\n",
    "i = 0\n",
    "for c in classes_:\n",
    "    classes[c] = i\n",
    "    i+=1\n",
    "\n",
    "# we convert classes into numerical indexes and add them to our data frame\n",
    "int_labels = []\n",
    "for x in data['label']:\n",
    "    int_labels.append(classes[x])\n",
    "\n",
    "data['label'] = int_labels\n",
    "\n",
    "# we find the weighs of all classes based on their inverse occurences\n",
    "class_weights = []\n",
    "for x in range(0,6):\n",
    "    class_weights.append(float(len(int_labels))/float(int_labels.count(x)))\n",
    "# normalization\n",
    "for i in range(0,6):\n",
    "    class_weights[i] = class_weights[i] / max(class_weights)\n",
    "print(\"Weights: \" + str(class_weights))\n",
    "\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0746a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, DataCollatorWithPadding, AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from torchsummary import summary\n",
    "from datasets import load_dataset,Dataset,DatasetDict,concatenate_datasets\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645afa4",
   "metadata": {},
   "source": [
    "Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1428f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we create the dataset and split it into train test and valid groups\n",
    "dataset = Dataset.from_pandas(data)\n",
    "train_test_valid = dataset.train_test_split(test_size=0.2, seed=seed)\n",
    "test_valid = train_test_valid['test'].train_test_split(test_size=0.5, seed=seed)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train':train_test_valid['train'], # first 80% for training\n",
    "    'test':test_valid['train'], # 10% for testing\n",
    "    'valid':test_valid['test'] # 10% for validation\n",
    "})\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3c6ab",
   "metadata": {},
   "source": [
    "We load bert model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94febc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the models tokenizer\n",
    "model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "#model = BertModel.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5db66",
   "metadata": {},
   "source": [
    "We tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e644d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1200/1200 [00:00<00:00, 1637.50 examples/s]\n",
      "Map: 100%|██████████| 150/150 [00:00<00:00, 1792.84 examples/s]\n",
      "Map: 100%|██████████| 150/150 [00:00<00:00, 1782.98 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch): # we tokenize the text field\n",
    "    return tokenizer(batch[\"text\"], truncation = True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset.set_format('torch', columns=['input_ids','token_type_ids','attention_mask','label'])\n",
    "\n",
    "# collator does some more preprocesing\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc13993",
   "metadata": {},
   "source": [
    "Creation of my model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SportClasifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, class_weights=None):\n",
    "        super(SportClasifier, self).__init__()\n",
    "        self.finetuning = False # do we want to train the whole model or just the head\n",
    "        hidden_size = 256\n",
    "        self.class_weights = torch.tensor(class_weights)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # we load the pretrained model based on its name\n",
    "        self.model = BertModel.from_pretrained(model_name, \n",
    "                                                    config = AutoConfig.from_pretrained(model_name, output_attention= True, output_hidden_state = True))\n",
    "\n",
    "        # we create clasification head\n",
    "        self.head = nn.Sequential(nn.Dropout(0.1), \n",
    "                                  nn.LazyLinear(out_features = hidden_size),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.1),\n",
    "                                  nn.LazyLinear(out_features = num_labels))\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids = None, token_type_ids=None ,attention_mask = None, labels = None):\n",
    "        outputs = self.model(input_ids = input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        last_hidden_state = None\n",
    "\n",
    "        if self.finetuning:\n",
    "            last_hidden_state = outputs[0]\n",
    "        else:\n",
    "            last_hidden_state = outputs[0].detach() # this stops the gradient from flowing backwards to the pretrained model\n",
    "        \n",
    "        logits = self.head(last_hidden_state[:,0,:].view(-1,768))\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_func = nn.CrossEntropyLoss(label_smoothing=0.05, weight = self.class_weights)\n",
    "            loss = loss_func(logits, labels) \n",
    "            return TokenClassifierOutput(loss=loss, logits=logits, hidden_states = outputs.hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f675f",
   "metadata": {},
   "source": [
    "Data loaders and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "601c2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "PATH = 'sports_model'\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "epochs_fine = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sport_model = SportClasifier(model_name=model_name, num_labels = 6, class_weights=class_weights).to(device)\n",
    "train_dataLoader = DataLoader(tokenized_dataset['train'], shuffle = True, batch_size=batch_size, collate_fn=data_collator)\n",
    "test_dataLoader = DataLoader(tokenized_dataset['test'], shuffle = True, collate_fn=data_collator)\n",
    "valid_dataLoader = DataLoader(tokenized_dataset['valid'], shuffle = True, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09f902",
   "metadata": {},
   "source": [
    "Training the head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e76164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [54:55<00:00,  7.32s/it]\n",
      "450it [54:55,  7.32s/it]00:00<?, ?it/s]\n",
      "100%|██████████| 150/150 [05:54<00:00,  6.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.6215108556832695}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [11:48,  6.46it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.6103738974497989}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 404/750 [15:40<14:37,  2.54s/it]  "
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# progress bars\n",
    "train_steps = epochs * len(train_dataLoader)\n",
    "progress_bar_train = tqdm(range(train_steps),position=0, leave=True)\n",
    "progress_bar_test = tqdm(range((len(test_dataLoader))), position=0, leave=True)\n",
    "\n",
    "\n",
    "# optimizer and scheduler\n",
    "optimizer = AdamW(sport_model.head.parameters(), lr = 5e-5)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=train_steps)\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sport_model.train()\n",
    "    for batch in train_dataLoader:\n",
    "        batch = {k : v.to(device) for k,v  in batch.items()}\n",
    "        outputs = sport_model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "\n",
    "    sport_model.eval()\n",
    "    for batch in test_dataLoader:\n",
    "        batch = {k : v.to(device) for k,v  in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = sport_model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions = predictions, references = batch['labels'])\n",
    "        progress_bar_test.update(1)\n",
    "    \n",
    "    print(metric.compute(average='weighted'))\n",
    "\n",
    "# we save the model\n",
    "torch.save(sport_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638df61",
   "metadata": {},
   "source": [
    "We load the model, if we don't want to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc9f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we load the saved model\n",
    "\n",
    "model = SportClasifier(model_name=model_name, num_labels = 6, class_weights=class_weights).to(device)\n",
    "\n",
    "state_dict = None\n",
    "pre_finetuned = True\n",
    "state_dict = torch.load(PATH, weights_only=True)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd597d",
   "metadata": {},
   "source": [
    "We evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.6390526315789474}\n"
     ]
    }
   ],
   "source": [
    "sport_model.eval()\n",
    "for batch in valid_dataLoader:\n",
    "        batch = {k : v.to(device) for k,v  in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = sport_model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions = predictions, references = batch['labels'])\n",
    "\n",
    "print(metric.compute(average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adbf2c2",
   "metadata": {},
   "source": [
    "Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa482a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [19:18<00:00,  2.58s/it]\n",
      "450it [19:18,  2.58s/it]00:00<?, ?it/s]\n",
      "100%|██████████| 150/150 [15:43<00:00,  5.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.435089748549323}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [31:30,  8.28it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.5648276934369649}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "450it [47:05,  7.08it/s] [46:46<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.7260003987240831}\n"
     ]
    }
   ],
   "source": [
    "# same thing as in previous traning block, but we train the whole model\n",
    "PATH_FINE = 'sports_model_finetuned'\n",
    "\n",
    "sport_model.finetuning = True\n",
    "train_steps = epochs_fine * len(train_dataLoader)\n",
    "progress_bar_train = tqdm(range(train_steps),position=0, leave=True)\n",
    "progress_bar_test = tqdm(range((len(test_dataLoader))), position=0, leave=True)\n",
    "\n",
    "optimizer = AdamW(sport_model.parameters(), lr = 5e-5)\n",
    "\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=train_steps)\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for epoch in range(epochs_fine):\n",
    "    sport_model.train()\n",
    "    for batch in train_dataLoader:\n",
    "        batch = {k : v.to(device) for k,v  in batch.items()}\n",
    "        outputs = sport_model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "\n",
    "    sport_model.eval()\n",
    "    for batch in test_dataLoader:\n",
    "        batch = {k : v.to(device) for k,v  in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = sport_model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions = predictions, references = batch['labels'])\n",
    "        progress_bar_test.update(1)\n",
    "    \n",
    "    print(metric.compute(average='weighted'))\n",
    "\n",
    "# we save the final model\n",
    "torch.save(sport_model.state_dict(), PATH_FINE)\n",
    "sport_model.finetuning = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7617a0",
   "metadata": {},
   "source": [
    "Post training evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c3c34",
   "metadata": {},
   "source": [
    "Loading the model for final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e87bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SportClasifier(model_name=model_name, num_labels = 6, class_weights=class_weights).to(device)\n",
    "\n",
    "state_dict = None\n",
    "pre_finetuned = True\n",
    "state_dict = torch.load(PATH_FINE, weights_only=True)\n",
    "\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3d86b",
   "metadata": {},
   "source": [
    "We evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8456458675424193}\n"
     ]
    }
   ],
   "source": [
    "sport_model.eval()\n",
    "for batch in valid_dataLoader:\n",
    "        batch = {k : v.to(device) for k,v  in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = sport_model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions = predictions, references = batch['labels'])\n",
    "\n",
    "print(metric.compute(average='weighted'))\n",
    "\n",
    "# epochs 1-1 = 0.78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
